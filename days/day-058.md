# Deploy Grafana on Kubernetes Cluster

The Nautilus DevOps team planned to deploy **Grafana** on a Kubernetes cluster to visualize and analyze application metrics.

In this task, we deployed Grafana using a Kubernetes **Deployment** and exposed it using a **NodePort Service**.

---

##  Objectives

1. Create a Deployment named:

```
grafana-deployment-datacenter
```

2. Use an official Grafana image.
3. Expose the application using a **NodePort Service**.
4. Set `nodePort` to:

```
32000
```

5. Ensure the Grafana login page is reachable.

---

#  Steps

## 1. Create Deployment YAML


[`grafana-deployment.yml`](../files/k8s_grafana_deployment_d58.yml)

Apply:

```bash
kubectl apply -f grafana-deployment.yaml
```

Verify:

```bash
kubectl get deployments
kubectl get pods
```

---

## 2. Create NodePort Service

File: `.yaml`
[`grafana-service.yml`](../files/k8s_grafana_service_d58.yml)
Apply:

```bash
kubectl apply -f grafana-service.yaml
```

---

# Good to Know

## Deployment

* Manages replica lifecycle
* Ensures desired state
* Automatically restarts failed containers

## Service (NodePort)

* Exposes application externally
* Maps internal port (3000) to nodePort (32000)
* Selects pods using labels

## Labels & Selectors

* `app: grafana` connects:

  * Deployment
  * Pod
  * Service

Without matching labels → service won’t route traffic.


### Why NodePort Range Starts at 30000

Kubernetes reserves:

```
30000 – 32767
```

for NodePort services to avoid conflicts with system ports.


### Why NodePort Didn't Work Directly in Browser

This lab runs inside a containerized environment:

* Node IP is internal
* No external routing
* Port forwarding required for access

In real production:

* Use Ingress
* Use LoadBalancer
* Or expose via reverse proxy


#  Production Improvements

For real-world deployments, consider:

* PersistentVolumeClaim (PVC) for dashboard storage
* Resource limits (CPU/Memory)
* Admin password via environment variables
* Ingress controller for HTTPS exposure
* Prometheus integration
